# Oracle存储过程3D调用链分析图谱详细设计方案

## 一、系统架构设计

### 1.1 整体架构

系统采用分层架构，包含五个核心模块：

```
┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐
│  解析器模块     │────▶│  图谱构建模块   │────▶│  API接口模块    │
│ (DeepSeek-NER)  │     │   (Neo4j)       │     │   (FastAPI)     │
└─────────────────┘     └─────────────────┘     └────────┬────────┘
                                                         │
                                                         ▼
                         ┌─────────────────┐     ┌─────────────────┐
                         │ 部署监控模块    │◀────│ 3D可视化模块    │
                         │ (Docker+ELK)    │     │  (Three.js)     │
                         └─────────────────┘     └─────────────────┘
```

### 1.2 技术栈选型

| 模块 | 技术选型 | 选型理由 |
|------|---------|----------|
| 解析器模块 | Python + DeepSeek-16B + NER | 代码解析需要语义理解能力，DeepSeek模型在代码理解上表现优异 |
| 图谱构建模块 | Neo4j 5.0+ | 图数据库适合存储和查询复杂关系网络，支持深度遍历算法 |
| API接口模块 | FastAPI + Uvicorn | 高性能异步框架，支持自动API文档生成 |
| 3D可视化模块 | Three.js + Vue3 | 3D渲染性能优异，支持大规模节点图谱展示 |
| 部署监控模块 | Docker + Kubernetes + ELK | 容器化部署便于扩展，ELK提供全链路日志分析 |

## 二、解析器模块设计

### 2.1 DeepSeek-NER模型设计

#### 2.1.1 实体类型定义

| 实体类型 | 说明 | 示例 |
|---------|------|------|
| SP | 存储过程名称 | SP_CALC_INTEREST |
| TABLE | 静态表引用 | T_CUSTOMER |
| DYN_TABLE | 动态表引用 | T_'||P_MONTH |
| SYNONYM | 同义词/视图 | SY_T_EMP |
| COLUMN | 表字段 | CUSTOMER_ID |

#### 2.1.2 训练数据构建

```python
# 训练数据格式示例
train_data = [
    {
        "text": "CREATE PROCEDURE SP_CALC_INTEREST AS BEGIN SELECT * FROM T_ACCOUNT; END;",
        "entities": [
            {"entity": "SP", "start": 18, "end": 34, "value": "SP_CALC_INTEREST"},
            {"entity": "TABLE", "start": 56, "end": 65, "value": "T_ACCOUNT"}
        ]
    },
    {
        "text": "EXECUTE IMMEDIATE 'SELECT * FROM T_'||P_MONTH||'_DATA';",
        "entities": [
            {"entity": "DYN_TABLE", "start": 27, "end": 47, "value": "T_'||P_MONTH||'_DATA"}
        ]
    }
]
```

#### 2.1.3 模型训练配置

```python
from transformers import AutoTokenizer, AutoModelForTokenClassification
from transformers import TrainingArguments, Trainer

# 加载DeepSeek-16B基础模型
tokenizer = AutoTokenizer.from_pretrained("deepseek-ai/deepseek-coder-16b-base")
model = AutoModelForTokenClassification.from_pretrained(
    "deepseek-ai/deepseek-coder-16b-base", 
    num_labels=len(entity_types)
)

# 训练参数
training_args = TrainingArguments(
    output_dir="./ner_model",
    learning_rate=5e-5,
    per_device_train_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
)

# 训练模型
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
)
trainer.train()
```

### 2.2 动态SQL解析器设计

#### 2.2.1 动态表名模式识别

```python
class DynamicSQLParser:
    def __init__(self, ner_model):
        self.ner_model = ner_model
        self.var_pattern = re.compile(r"\|{2}\s*([A-Z_]+)")
    
    def extract_dynamic_tables(self, sql_text):
        # 使用NER模型识别动态表引用
        entities = self.ner_model.predict(sql_text)
        dynamic_tables = [e for e in entities if e["entity"] == "DYN_TABLE"]
        
        # 提取变量并分析
        for table in dynamic_tables:
            table_pattern = table["value"]
            variables = self.var_pattern.findall(table_pattern)
            table["variables"] = variables
            table["confidence"] = 0.7  # 动态表默认置信度
        
        return dynamic_tables
    
    def resolve_with_runtime_logs(self, dynamic_table, runtime_logs):
        """结合运行时日志解析实际表名"""
        # 示例：从日志中提取P_MONTH=202404的实际执行情况
        for var in dynamic_table["variables"]:
            if var in runtime_logs:
                # 替换变量为实际值
                actual_value = runtime_logs[var]
                pattern = table_pattern.replace(f"||{var}", actual_value)
                dynamic_table["resolved_name"] = pattern
                dynamic_table["confidence"] = 0.9  # 提高置信度
        
        return dynamic_table
```

#### 2.2.2 同义词解析

```python
class SynonymResolver:
    def __init__(self, oracle_connection):
        self.connection = oracle_connection
    
    def load_synonyms(self):
        """从Oracle数据字典加载同义词映射"""
        query = """SELECT synonym_name, table_owner, table_name 
                  FROM all_synonyms"""
        cursor = self.connection.cursor()
        cursor.execute(query)
        
        synonym_map = {}
        for row in cursor:
            synonym_name, owner, table_name = row
            synonym_map[synonym_name] = f"{owner}.{table_name}"
        
        return synonym_map
    
    def resolve_synonym(self, table_name, synonym_map):
        """解析表名的同义词引用"""
        if table_name in synonym_map:
            return {
                "original": table_name,
                "resolved": synonym_map[table_name],
                "confidence": 1.0  # 同义词映射确定性为1.0
            }
        return {"original": table_name, "resolved": table_name, "confidence": 1.0}
```

## 三、图谱构建模块设计

### 3.1 Neo4j数据模型

#### 3.1.1 节点设计

```cypher
// 存储过程节点
CREATE (:SP_Node {
    name: "SP_CALC_INTEREST",       // 存储过程名称
    type: "PROCEDURE",             // 类型：PROCEDURE/FUNCTION
    schema: "FINANCE",             // 所属模式
    last_modified: "2024-04-01",   // 最后修改时间
    complexity: 3                  // 复杂度评分(1-5)
})

// 表节点
CREATE (:Table_Node {
    name: "T_ACCOUNT",              // 表名
    schema: "FINANCE",             // 所属模式
    is_core: true,                 // 是否核心表
    record_count: 1500000          // 记录数量
})

// 动态表节点
CREATE (:DYN_Table_Node {
    pattern: "T_${P_MONTH}",        // 表名模式
    example: "T_202404",           // 示例实例
    variables: ["P_MONTH"],        // 依赖变量
    confidence: 0.7                // 置信度
})
```

#### 3.1.2 关系设计

```cypher
// 调用关系（SP之间）
CREATE (caller:SP_Node)-[r:CALLS {
    depth: 1,                      // 调用深度
    frequency: 5,                 // 调用频率
    is_conditional: false,        // 是否条件调用
    confidence: 1.0               // 置信度
}]->(callee:SP_Node)

// 引用关系（SP到表）
CREATE (sp:SP_Node)-[r:REFERENCES {
    operation: "SELECT",           // 操作类型：SELECT/INSERT/UPDATE/DELETE
    is_dynamic: false,            // 是否动态引用
    confidence: 1.0,              // 置信度
    last_verified: "2024-04-01"   // 最后验证时间
}]->(table:Table_Node)

// 动态引用关系
CREATE (sp:SP_Node)-[r:DYN_REFERENCES {
    operation: "SELECT",           // 操作类型
    pattern: "T_${P_MONTH}",      // 表名模式
    variables: ["P_MONTH"],       // 依赖变量
    confidence: 0.7,              // 置信度
    need_verify: true             // 是否需要验证
}]->(dyn_table:DYN_Table_Node)
```

### 3.2 图谱查询设计

#### 3.2.1 调用链深度查询

```cypher
// 查询SP_A的3层调用链（包含表依赖）
MATCH path = (start:SP_Node {name: "SP_A"})-[:CALLS*1..3]->(sp:SP_Node)
OPTIONAL MATCH (sp)-[ref:REFERENCES]->(table:Table_Node)
RETURN path, sp, ref, table

// 带置信度过滤的查询
MATCH path = (start:SP_Node {name: "SP_A"})-[call:CALLS*1..3]->(sp:SP_Node)
WHERE ALL(r IN call WHERE r.confidence >= 0.7)
OPTIONAL MATCH (sp)-[ref:REFERENCES]->(table:Table_Node)
WHERE ref.confidence >= 0.7
RETURN path, sp, ref, table
```

#### 3.2.2 影响分析查询

```cypher
// 计算修改SP_A可能影响的所有节点
MATCH (start:SP_Node {name: "SP_A"})
CALL apoc.path.expandConfig(start, {
    relationshipFilter: "CALLS|REFERENCES",
    minLevel: 1,
    maxLevel: 5
})
YIELD path
WITH DISTINCT last(nodes(path)) AS affected_node
RETURN 
    count(affected_node) AS total_affected,
    sum(CASE WHEN affected_node:SP_Node THEN 1 ELSE 0 END) AS affected_sps,
    sum(CASE WHEN affected_node:Table_Node THEN 1 ELSE 0 END) AS affected_tables
```

## 四、API接口模块设计

### 4.1 FastAPI接口设计

#### 4.1.1 数据模型

```python
from pydantic import BaseModel
from typing import List, Optional

class NodeBase(BaseModel):
    id: str
    name: str
    type: str

class SPNode(NodeBase):
    schema: str
    last_modified: str
    complexity: int

class TableNode(NodeBase):
    schema: str
    is_core: bool

class EdgeBase(BaseModel):
    source: str
    target: str
    type: str
    confidence: float

class CallsEdge(EdgeBase):
    depth: int
    frequency: int

class ReferencesEdge(EdgeBase):
    operation: str
    is_dynamic: bool

class GraphData(BaseModel):
    nodes: List[NodeBase]
    edges: List[EdgeBase]

class ImpactAnalysis(BaseModel):
    affected_nodes: int
    affected_sps: int
    affected_tables: int
    risk_level: str
    confidence: float
```

#### 4.1.2 API端点设计

```python
from fastapi import FastAPI, Query, HTTPException
from neo4j import GraphDatabase

app = FastAPI(title="Oracle SP调用链分析API")

@app.get("/api/graph", response_model=GraphData)
async def get_graph(node: str, depth: int = Query(1, ge=1, le=5), confidence: float = Query(0.5, ge=0, le=1.0)):
    """获取指定节点的调用图谱数据"""
    # 连接Neo4j并执行查询
    # 返回GraphData对象

@app.get("/api/impact", response_model=ImpactAnalysis)
async def analyze_impact(node: str, depth: int = Query(3, ge=1, le=5)):
    """分析指定节点的影响范围"""
    # 执行影响分析查询
    # 计算风险等级
    # 返回ImpactAnalysis对象

@app.get("/api/path")
async def find_path(source: str, target: str, max_depth: int = Query(5, ge=1, le=10)):
    """查找两个节点之间的路径"""
    # 执行路径查询
    # 返回路径数据

@app.post("/api/verify")
async def verify_dependency(node_id: str, verified: bool = True):
    """验证依赖关系并更新置信度"""
    # 更新依赖关系的验证状态
    # 提高置信度
```

## 五、3D可视化模块设计

### 5.1 Three.js图谱渲染

#### 5.1.1 节点与边渲染

```javascript
import { ForceGraph3D } from 'three-force-graph';

class Graph3DRenderer {
    constructor(containerId) {
        this.container = document.getElementById(containerId);
        this.graph = ForceGraph3D()(this.container)
            .nodeLabel(node => this.generateNodeTooltip(node))
            .nodeColor(node => this.getNodeColor(node))
            .nodeVal(node => this.getNodeSize(node))
            .linkWidth(link => link.confidence * 3) // 置信度影响线宽
            .linkColor(link => this.getLinkColor(link))
            .onNodeClick(node => this.handleNodeClick(node));
    }
    
    getNodeColor(node) {
        // 根据节点类型设置颜色
        if (node.type === 'SP') return '#ff6b6b'; // 红色
        if (node.type === 'TABLE') return '#4ecdc4'; // 青色
        if (node.type === 'DYN_TABLE') return '#ffd166'; // 黄色
        return '#ced4da'; // 默认灰色
    }
    
    getLinkColor(link) {
        // 根据关系类型和置信度设置颜色
        if (link.type === 'CALLS') {
            return `rgba(255, 0, 0, ${link.confidence})`; // 红色调用关系
        }
        if (link.type === 'REFERENCES') {
            return `rgba(0, 0, 255, ${link.confidence})`; // 蓝色引用关系
        }
        if (link.type === 'DYN_REFERENCES') {
            return `rgba(255, 165, 0, ${link.confidence})`; // 橙色动态引用
        }
        return '#999'; // 默认灰色
    }
    
    getNodeSize(node) {
        // 根据节点重要性设置大小
        if (node.is_core) return 8;
        if (node.type === 'SP' && node.complexity > 3) return 7;
        return 5;
    }
    
    generateNodeTooltip(node) {
        // 生成节点悬停提示
        let tooltip = `<div class="tooltip">`;
        tooltip += `<div class="title">${node.name}</div>`;
        tooltip += `<div class="type">${node.type}</div>`;
        
        if (node.type === 'SP') {
            tooltip += `<div>复杂度: ${node.complexity}</div>`;
            tooltip += `<div>最后修改: ${node.last_modified}</div>`;
        }
        
        if (node.type === 'TABLE' || node.type === 'DYN_TABLE') {
            tooltip += `<div>模式: ${node.schema}</div>`;
            if (node.is_core) tooltip += `<div class="warning">核心表</div>`;
        }
        
        tooltip += `</div>`;
        return tooltip;
    }
    
    handleNodeClick(node) {
        // 点击节点时高亮相关路径
        this.highlightRelatedNodes(node.id);
        // 显示节点详情面板
        this.showNodeDetails(node);
    }
    
    highlightRelatedNodes(nodeId) {
        // 实现高亮相关节点的逻辑
    }
    
    loadGraphData(data) {
        this.graph.graphData(data);
    }
}
```

#### 5.1.2 交互功能设计

```javascript
class GraphInteraction {
    constructor(renderer) {
        this.renderer = renderer;
        this.setupControls();
    }
    
    setupControls() {
        // 搜索功能
        document.getElementById('search-btn').addEventListener('click', () => {
            const searchTerm = document.getElementById('search-input').value;
            this.searchNode(searchTerm);
        });
        
        // 置信度过滤器
        document.getElementById('confidence-slider').addEventListener('input', (e) => {
            const threshold = parseFloat(e.target.value);
            this.filterByConfidence(threshold);
        });
        
        // 深度控制
        document.getElementById('depth-select').addEventListener('change', (e) => {
            const depth = parseInt(e.target.value);
            this.changeDepth(depth);
        });
        
        // 视图切换（2D/3D）
        document.getElementById('view-toggle').addEventListener('click', () => {
            this.toggleView();
        });
    }
    
    searchNode(term) {
        // 实现节点搜索逻辑
        fetch(`/api/search?term=${encodeURIComponent(term)}`)
            .then(res => res.json())
            .then(data => {
                if (data.nodes.length > 0) {
                    // 高亮搜索到的节点
                    this.renderer.focusOnNode(data.nodes[0].id);
                }
            });
    }
    
    filterByConfidence(threshold) {
        // 根据置信度过滤边
        const graphData = this.renderer.graph.graphData();
        const filteredLinks = graphData.links.filter(link => link.confidence >= threshold);
        
        // 更新图谱数据
        this.renderer.graph.graphData({
            nodes: graphData.nodes,
            links: filteredLinks
        });
    }
    
    changeDepth(depth) {
        // 更改调用链深度
        const currentNode = this.renderer.currentFocusNode;
        if (currentNode) {
            fetch(`/api/graph?node=${currentNode.id}&depth=${depth}`)
                .then(res => res.json())
                .then(data => {
                    this.renderer.loadGraphData(data);
                });
        }
    }
    
    toggleView() {
        // 在2D和3D视图之间切换
        this.renderer.toggle2D3D();
    }
}
```

## 六、部署监控模块设计

### 6.1 Docker容器化设计

#### 6.1.1 服务容器定义

```yaml
# docker-compose.yml
version: '3.8'

services:
  # 解析器服务
  parser:
    build: ./parser
    volumes:
      - ./data/sp_files:/app/sp_files
      - ./data/models:/app/models
    environment:
      - ORACLE_CONNECTION_STRING=user/pass@host:port/service
    depends_on:
      - neo4j
  
  # Neo4j图数据库
  neo4j:
    image: neo4j:5.10
    ports:
      - "7474:7474"  # HTTP
      - "7687:7687"  # Bolt
    volumes:
      - ./data/neo4j:/data
      - ./data/neo4j/logs:/logs
    environment:
      - NEO4J_AUTH=neo4j/password
      - NEO4J_dbms_memory_heap_max__size=4G
  
  # API服务
  api:
    build: ./api
    ports:
      - "8000:8000"
    environment:
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=password
    depends_on:
      - neo4j
  
  # 前端服务
  frontend:
    build: ./frontend
    ports:
      - "3000:80"
    depends_on:
      - api
  
  # ELK日志收集
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.14.0
    environment:
      - discovery.type=single-node
    volumes:
      - ./data/elasticsearch:/usr/share/elasticsearch/data
  
  logstash:
    image: docker.elastic.co/logstash/logstash:7.14.0
    volumes:
      - ./config/logstash:/usr/share/logstash/pipeline
    depends_on:
      - elasticsearch
  
  kibana:
    image: docker.elastic.co/kibana/kibana:7.14.0
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
```

### 6.2 监控告警设计

#### 6.2.1 性能指标监控

```yaml
# prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'neo4j'
    static_configs:
      - targets: ['neo4j:2004']
  
  - job_name: 'api'
    static_configs:
      - targets: ['api:8000']

  - job_name: 'parser'
    static_configs:
      - targets: ['parser:9090']
```

#### 6.2.2 告警规则

```yaml
# alert_rules.yml
groups:
  - name: oracle_sp_analyzer
    rules:
      # Neo4j内存使用率告警
      - alert: Neo4jHighMemoryUsage
        expr: neo4j_jvm_memory_used_bytes / neo4j_jvm_memory_max_bytes > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Neo4j内存使用率高 ({{ $value | humanizePercentage }})"
          description: "Neo4j实例内存使用率超过80%已持续5分钟"
      
      # API响应时间告警
      - alert: ApiHighResponseTime
        expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le)) > 0.5
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "API响应时间过长"
          description: "95%的API请求响应时间超过500ms已持续2分钟"
      
      # 解析错误率告警
      - alert: HighParsingErrorRate
        expr: rate(sp_parser_errors_total[5m]) / rate(sp_parser_attempts_total[5m]) > 0.1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "存储过程解析错误率高"
          description: "存储过程解析错误率超过10%已持续5分钟"
```

## 七、系统扩展设计

### 7.1 MySQL存储过程适配器

```python
from abc import ABC, abstractmethod

# 解析器接口
class SPParserAdapter(ABC):
    @abstractmethod
    def parse_file(self, file_path):
        pass
    
    @abstractmethod
    def extract_dependencies(self, code):
        pass

# Oracle存储过程解析器
class OracleSPParser(SPParserAdapter):
    def __init__(self, ner_model):
        self.ner_model = ner_model
    
    def parse_file(self, file_path):
        # 解析.bdy文件
        pass
    
    def extract_dependencies(self, code):
        # 提取Oracle存储过程依赖
        pass

# MySQL存储过程解析器
class MySQLSPParser(SPParserAdapter):
    def __init__(self, ner_model):
        self.ner_model = ner_model
    
    def parse_file(self, file_path):
        # 解析MySQL存储过程文件
        pass
    
    def extract_dependencies(self, code):
        # 提取MySQL存储过程依赖
        pass

# 解析器工厂
class SPParserFactory:
    @staticmethod
    def create_parser(db_type, ner_model):
        if db_type.lower() == "oracle":
            return OracleSPParser(ner_model)
        elif db_type.lower() == "mysql":
            return MySQLSPParser(ner_model)
        else:
            raise ValueError(f"不支持的数据库类型: {db_type}")
```

### 7.2 实时监控扩展

```python
class RealTimeMonitor:
    def __init__(self, connection_string):
        self.connection_string = connection_string
        self.active_sessions = {}
        self.execution_history = []
    
    def start_monitoring(self):
        """启动实时监控Oracle执行的存储过程"""
        # 连接Oracle数据库
        import cx_Oracle
        import threading
        import time
        
        self.conn = cx_Oracle.connect(self.connection_string)
        self.running = True
        
        # 启动监控线程
        self.monitor_thread = threading.Thread(target=self._monitor_loop)
        self.monitor_thread.daemon = True
        self.monitor_thread.start()
        
        print("实时监控已启动，正在监控存储过程执行情况...")
    
    def _monitor_loop(self):
        """监控循环，定期检查活动会话"""
        while self.running:
            try:
                cursor = self.conn.cursor()
                # 查询正在执行的存储过程
                query = """
                SELECT s.sid, s.serial#, s.username, s.program, 
                       s.module, s.action, s.sql_id, q.sql_text,
                       s.logon_time, s.status, s.machine
                FROM v$session s
                LEFT JOIN v$sql q ON s.sql_id = q.sql_id
                WHERE s.type = 'USER'
                AND s.module LIKE '%PROCEDURE%'
                OR s.module LIKE '%FUNCTION%'
                """
                cursor.execute(query)
                
                current_time = time.time()
                active_sids = set()
                
                for row in cursor:
                    sid = row[0]
                    active_sids.add(sid)
                    
                    # 记录会话信息
                    if sid not in self.active_sessions:
                        self.active_sessions[sid] = {
                            'sid': sid,
                            'serial': row[1],
                            'username': row[2],
                            'program': row[3],
                            'module': row[4],
                            'action': row[5],
                            'sql_id': row[6],
                            'sql_text': row[7],
                            'start_time': current_time,
                            'machine': row[10]
                        }
                        # 记录新的存储过程执行
                        self._log_sp_execution(self.active_sessions[sid])
                
                # 清理已结束的会话
                ended_sessions = set(self.active_sessions.keys()) - active_sids
                for sid in ended_sessions:
                    session = self.active_sessions.pop(sid)
                    session['end_time'] = current_time
                    session['duration'] = current_time - session['start_time']
                    # 记录执行历史
                    self.execution_history.append(session)
                    # 更新执行结束状态
                    self._update_sp_execution(session)
                
                cursor.close()
                time.sleep(2)  # 每2秒检查一次
                
            except Exception as e:
                print(f"监控异常: {str(e)}")
                time.sleep(5)  # 发生异常时，等待时间更长
    
    def _log_sp_execution(self, session):
        """记录存储过程执行开始"""
        # 将执行信息写入日志或数据库
        print(f"检测到存储过程执行: {session['module']} - {session['action']}")
    
    def _update_sp_execution(self, session):
        """更新存储过程执行结束状态"""
        # 更新执行状态
        print(f"存储过程执行结束: {session['module']} - 耗时: {session['duration']:.2f}秒")
    
    def capture_dynamic_dependencies(self):
        """捕获动态SQL执行情况"""
        cursor = self.conn.cursor()
        # 监控V$SQL视图获取动态SQL
        query = """
        SELECT sql_id, parsing_schema_name, module, sql_text
        FROM v$sql
        WHERE module LIKE '%PROCEDURE%'
        AND sql_text LIKE '%EXECUTE IMMEDIATE%'
        ORDER BY last_active_time DESC
        """
        cursor.execute(query)
        
        dynamic_sqls = []
        for row in cursor:
            dynamic_sqls.append({
                'sql_id': row[0],
                'schema': row[1],
                'module': row[2],
                'sql_text': row[3]
            })
        
        cursor.close()
        return dynamic_sqls
    
    def stop_monitoring(self):
        """停止监控"""
        self.running = False
        if hasattr(self, 'conn') and self.conn:
            self.conn.close()
        print("实时监控已停止")
```

### 7.3 批量分析功能

```python
class BatchAnalyzer:
    def __init__(self, parser_factory, graph_builder):
        self.parser_factory = parser_factory
        self.graph_builder = graph_builder
        self.results = {}
    
    async def analyze_directory(self, directory_path, db_type="oracle"):
        """批量分析目录中的所有存储过程文件"""
        import os
        import asyncio
        from tqdm import tqdm
        
        # 获取适合的解析器
        parser = self.parser_factory.create_parser(db_type, None)  # 先不传入NER模型
        
        # 查找所有存储过程文件
        sp_files = []
        for root, _, files in os.walk(directory_path):
            for file in files:
                if db_type.lower() == "oracle" and file.endswith(".bdy"):
                    sp_files.append(os.path.join(root, file))
                elif db_type.lower() == "mysql" and file.endswith(".sql"):
                    sp_files.append(os.path.join(root, file))
        
        print(f"找到{len(sp_files)}个存储过程文件，开始批量分析...")
        
        # 创建分析任务
        tasks = []
        for file_path in sp_files:
            tasks.append(self._analyze_file(file_path, parser))
        
        # 使用进度条显示分析进度
        with tqdm(total=len(tasks)) as pbar:
            for future in asyncio.as_completed(tasks):
                result = await future
                self.results[result['file']] = result
                pbar.update(1)
        
        # 构建完整图谱
        self._build_complete_graph()
        
        return self.results
    
    async def _analyze_file(self, file_path, parser):
        """分析单个文件"""
        try:
            # 解析文件
            sp_info = parser.parse_file(file_path)
            
            # 提取依赖关系
            with open(file_path, 'r', encoding='utf-8') as f:
                code = f.read()
            
            dependencies = parser.extract_dependencies(code)
            
            return {
                'file': file_path,
                'sp_name': sp_info.get('name', os.path.basename(file_path)),
                'dependencies': dependencies,
                'status': 'success'
            }
        except Exception as e:
            return {
                'file': file_path,
                'status': 'error',
                'error': str(e)
            }
    
    def _build_complete_graph(self):
        """构建完整的调用图谱"""
        # 将所有分析结果添加到图谱
        for file_path, result in self.results.items():
            if result['status'] == 'success':
                self.graph_builder.add_stored_procedure(result['sp_name'], result['dependencies'])
        
        # 构建图谱关系
        self.graph_builder.build_relationships()
        
        print("完整图谱构建完成")
    
    def generate_report(self, output_path):
        """生成分析报告"""
        import json
        
        # 统计信息
        total = len(self.results)
        success = sum(1 for r in self.results.values() if r['status'] == 'success')
        error = total - success
        
        # 依赖统计
        sp_calls = {}
        table_refs = {}
        
        for result in self.results.values():
            if result['status'] == 'success':
                for dep in result['dependencies']:
                    if dep['type'] == 'SP':
                        sp_calls[dep['name']] = sp_calls.get(dep['name'], 0) + 1
                    elif dep['type'] in ['TABLE', 'DYN_TABLE']:
                        table_refs[dep['name']] = table_refs.get(dep['name'], 0) + 1
        
        # 生成报告
        report = {
            'summary': {
                'total': total,
                'success': success,
                'error': error,
                'success_rate': f"{success/total*100:.2f}%" if total > 0 else "0%"
            },
            'top_called_sps': sorted(sp_calls.items(), key=lambda x: x[1], reverse=True)[:10],
            'top_referenced_tables': sorted(table_refs.items(), key=lambda x: x[1], reverse=True)[:10],
            'error_files': [r['file'] for r in self.results.values() if r['status'] == 'error']
        }
        
        # 保存报告
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"分析报告已生成: {output_path}")
        return report
```

### 7.4 历史版本比对功能

```python
class VersionComparer:
    def __init__(self, parser_factory):
        self.parser_factory = parser_factory
    
    def compare_versions(self, old_file, new_file, db_type="oracle"):
        """比较存储过程的两个版本"""
        # 获取解析器
        parser = self.parser_factory.create_parser(db_type, None)
        
        # 解析两个版本
        with open(old_file, 'r', encoding='utf-8') as f:
            old_code = f.read()
        
        with open(new_file, 'r', encoding='utf-8') as f:
            new_code = f.read()
        
        # 提取依赖关系
        old_deps = parser.extract_dependencies(old_code)
        new_deps = parser.extract_dependencies(new_code)
        
        # 比较依赖变化
        added_deps = [d for d in new_deps if d not in old_deps]
        removed_deps = [d for d in old_deps if d not in new_deps]
        unchanged_deps = [d for d in new_deps if d in old_deps]
        
        # 计算影响范围
        impact = self._calculate_impact(added_deps, removed_deps)
        
        return {
            'old_version': old_file,
            'new_version': new_file,
            'changes': {
                'added_dependencies': added_deps,
                'removed_dependencies': removed_deps,
                'unchanged_dependencies': unchanged_deps,
            },
            'impact_assessment': impact
        }
    
    def _calculate_impact(self, added_deps, removed_deps):
        """计算变更影响范围"""
        # 根据依赖变化评估影响
        impact_level = "低"
        impact_reason = []
        
        # 检查是否有核心表变更
        core_tables_changed = any(d['is_core'] for d in added_deps + removed_deps 
                                if d['type'] in ['TABLE', 'DYN_TABLE'])
        
        if core_tables_changed:
            impact_level = "高"
            impact_reason.append("核心表引用发生变化")
        
        # 检查是否有大量依赖变更
        if len(added_deps) + len(removed_deps) > 5:
            impact_level = "中" if impact_level == "低" else impact_level
            impact_reason.append(f"大量依赖变更({len(added_deps)}新增, {len(removed_deps)}移除)")
        
        # 检查是否有动态SQL变更
        dyn_sql_changed = any(d['is_dynamic'] for d in added_deps + removed_deps 
                             if d['type'] in ['TABLE', 'DYN_TABLE'])
        
        if dyn_sql_changed:
            impact_level = "中" if impact_level == "低" else impact_level
            impact_reason.append("动态SQL引用发生变化")
        
        return {
            'level': impact_level,
            'reasons': impact_reason,
            'affected_objects_count': len(added_deps) + len(removed_deps)
        }
    
    def generate_diff_report(self, comparison_result, output_path):
        """生成版本比对报告"""
        import json
        
        # 保存比对结果
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(comparison_result, f, ensure_ascii=False, indent=2)
        
        print(f"版本比对报告已生成: {output_path}")
        return comparison_result
```

### 7.5 安全风险评估功能

```python
class SecurityAnalyzer:
    def __init__(self):
        self.risk_patterns = [
            {
                'pattern': r'EXECUTE\s+IMMEDIATE',
                'risk_level': '高',
                'description': '使用动态SQL，可能存在SQL注入风险'
            },
            {
                'pattern': r'DBMS_SQL\.PARSE',
                'risk_level': '高',
                'description': '使用DBMS_SQL包动态执行SQL，可能存在注入风险'
            },
            {
                'pattern': r'GRANT\s+',
                'risk_level': '高',
                'description': '授予权限操作，可能导致权限提升'
            },
            {
                'pattern': r'UTL_FILE',
                'risk_level': '中',
                'description': '文件操作，可能存在文件系统访问风险'
            },
            {
                'pattern': r'UTL_HTTP',
                'risk_level': '中',
                'description': '网络请求，可能存在网络安全风险'
            },
            {
                'pattern': r'UTL_SMTP',
                'risk_level': '中',
                'description': '邮件发送，可能被用于数据泄露'
            },
            {
                'pattern': r'DBMS_JOB',
                'risk_level': '中',
                'description': '作业调度，可能被用于执行恶意代码'
            },
            {
                'pattern': r'DELETE\s+FROM\s+\w+\s+(?!WHERE)',
                'risk_level': '中',
                'description': '无条件删除表数据，可能导致数据丢失'
            },
            {
                'pattern': r'DROP\s+TABLE',
                'risk_level': '高',
                'description': '删除表操作，可能导致数据丢失'
            },
            {
                'pattern': r'ALTER\s+USER',
                'risk_level': '高',
                'description': '修改用户信息，可能存在权限风险'
            }
        ]
    
    def analyze_sp_security(self, sp_code):
        """分析存储过程的安全风险"""
        import re
        
        findings = []
        lines = sp_code.split('\n')
        
        for i, line in enumerate(lines):
            for risk in self.risk_patterns:
                if re.search(risk['pattern'], line, re.IGNORECASE):
                    findings.append({
                        'line_number': i + 1,
                        'line_content': line.strip(),
                        'risk_level': risk['risk_level'],
                        'description': risk['description'],
                        'pattern': risk['pattern']
                    })
        
        # 计算总体风险等级
        risk_score = self._calculate_risk_score(findings)
        
        return {
            'findings': findings,
            'total_issues': len(findings),
            'risk_score': risk_score,
            'risk_level': self._get_risk_level(risk_score),
            'recommendations': self._generate_recommendations(findings)
        }
    
    def _calculate_risk_score(self, findings):
        """计算风险评分"""
        # 根据风险等级计算分数
        score = 0
        for finding in findings:
            if finding['risk_level'] == '高':
                score += 10
            elif finding['risk_level'] == '中':
                score += 5
            else:
                score += 2
        
        return score
    
    def _get_risk_level(self, score):
        """根据分数确定风险等级"""
        if score >= 30:
            return '高'
        elif score >= 15:
            return '中'
        else:
            return '低'
    
    def _generate_recommendations(self, findings):
        """生成安全建议"""
        recommendations = []
        
        # 根据发现的问题生成建议
        if any(f['risk_level'] == '高' for f in findings):
            recommendations.append("对高风险操作进行代码审查，确保有适当的权限控制和输入验证")
        
        if any(f['pattern'] == r'EXECUTE\s+IMMEDIATE' for f in findings):
            recommendations.append("使用参数化查询替代动态SQL，避免SQL注入风险")
        
        if any(f['pattern'] == r'DELETE\s+FROM\s+\w+\s+(?!WHERE)' for f in findings):
            recommendations.append("为DELETE操作添加WHERE条件，避免意外删除所有数据")
        
        if any(f['pattern'] in [r'UTL_FILE', r'UTL_HTTP', r'UTL_SMTP'] for f in findings):
            recommendations.append("限制UTL包的使用权限，仅授予必要的用户访问权限")
        
        # 添加通用建议
        if len(recommendations) == 0:
            recommendations.append("定期进行代码安全审查，遵循最小权限原则")
        
        return recommendations
    
    def batch_security_scan(self, directory_path):
        """批量扫描目录中的存储过程安全风险"""
        import os
        from tqdm import tqdm
        
        results = {}
        sp_files = []
        
        # 查找所有存储过程文件
        for root, _, files in os.walk(directory_path):
            for file in files:
                if file.endswith(".bdy") or file.endswith(".sql"):
                    sp_files.append(os.path.join(root, file))
        
        print(f"找到{len(sp_files)}个存储过程文件，开始安全扫描...")
        
        # 扫描每个文件
        for file_path in tqdm(sp_files):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    code = f.read()
                
                # 分析安全风险
                scan_result = self.analyze_sp_security(code)
                scan_result['file_path'] = file_path
                
                results[file_path] = scan_result
            except Exception as e:
                results[file_path] = {
                    'error': str(e),
                    'file_path': file_path
                }
        
        # 生成汇总报告
        summary = {
            'total_files': len(sp_files),
            'files_with_issues': sum(1 for r in results.values() if 'total_issues' in r and r['total_issues'] > 0),
            'high_risk_files': sum(1 for r in results.values() if 'risk_level' in r and r['risk_level'] == '高'),
            'medium_risk_files': sum(1 for r in results.values() if 'risk_level' in r and r['risk_level'] == '中'),
            'low_risk_files': sum(1 for r in results.values() if 'risk_level' in r and r['risk_level'] == '低'),
            'error_files': sum(1 for r in results.values() if 'error' in r)
        }
        
        return {
            'summary': summary,
            'detailed_results': results
        }
```

## 八、总结与展望

### 8.1 系统优势

1. **深度语义理解**：利用DeepSeek-16B大模型进行存储过程代码的语义理解，相比传统正则表达式解析更准确。

2. **动态SQL解析**：创新性地解决了Oracle存储过程中动态SQL解析难题，提高了依赖关系识别的准确性。

3. **3D可视化**：采用Three.js实现的3D调用链可视化，直观展示复杂依赖关系，支持多维度交互。

4. **实时监控**：通过数据库性能视图实时捕获存储过程执行情况，验证静态分析结果。

5. **多数据库支持**：采用适配器模式设计，可扩展支持MySQL等多种数据库的存储过程分析。

### 8.2 应用场景

1. **代码重构评估**：在大型存储过程重构前，评估影响范围和风险。

2. **性能优化**：识别调用频繁的核心存储过程，优先进行性能优化。

3. **安全审计**：发现存储过程中的安全风险，如SQL注入漏洞和权限问题。

4. **知识传承**：帮助新团队成员快速理解复杂的存储过程调用关系。

5. **版本管理**：比对不同版本的存储过程变更，评估升级风险。

### 8.3 未来展望

1. **自动修复建议**：基于大模型分析，为存储过程中的性能问题和安全风险提供自动修复建议。

2. **跨数据库迁移**：支持Oracle到MySQL、PostgreSQL等数据库的存储过程自动转换。

3. **业务流程挖掘**：结合业务元数据，从存储过程调用链中挖掘业务流程。

4. **自适应监控**：根据系统负载自动调整监控频率和深度，减少性能影响。

5. **云原生部署**：优化系统架构，支持Kubernetes集群部署和弹性扩展。